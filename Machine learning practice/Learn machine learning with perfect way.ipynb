{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are 6 top level task for build a machine learning model\n",
    "\n",
    "1. Define Problem: Investigate and characterize the problem in order to better understand\n",
    "the goals of the project.\n",
    "\n",
    "2. Analyze Data: Use descriptive statistics and visualization to better understand the data\n",
    "you have available.\n",
    "3. Prepare Data: Use data transforms in order to better expose the structure of the\n",
    "prediction problem to modeling algorithms.\n",
    "4. Evaluate Algorithms: Design a test harness to evaluate a number of standard algorithms\n",
    "on the data and select the top few to investigate further.\n",
    "5. Improve Results: Use algorithm tuning and ensemble methods to get the most out of\n",
    "well-performing algorithms on your data.\n",
    "6. Present Results: Finalize the model, make predictions and present results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step:3  Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[: , 0:8]\n",
    "y = array[:, 8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Rescale Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import set_printoptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "reScaledX = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.353, 0.744, 0.59 , ..., 0.501, 0.234, 0.483],\n",
       "       [0.059, 0.427, 0.541, ..., 0.396, 0.117, 0.167],\n",
       "       [0.471, 0.92 , 0.525, ..., 0.347, 0.254, 0.183],\n",
       "       ...,\n",
       "       [0.294, 0.608, 0.59 , ..., 0.39 , 0.071, 0.15 ],\n",
       "       [0.059, 0.633, 0.492, ..., 0.449, 0.116, 0.433],\n",
       "       [0.059, 0.467, 0.574, ..., 0.453, 0.101, 0.033]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_printoptions(precision=3)\n",
    "reScaledX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "reScaledX = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64 ,  0.848,  0.15 , ...,  0.204,  0.468,  1.426],\n",
       "       [-0.845, -1.123, -0.161, ..., -0.684, -0.365, -0.191],\n",
       "       [ 1.234,  1.944, -0.264, ..., -1.103,  0.604, -0.106],\n",
       "       ...,\n",
       "       [ 0.343,  0.003,  0.15 , ..., -0.735, -0.685, -0.276],\n",
       "       [-0.845,  0.16 , -0.471, ..., -0.24 , -0.371,  1.171],\n",
       "       [-0.845, -0.873,  0.046, ..., -0.202, -0.474, -0.871]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_printoptions(precision=3)\n",
    "reScaledX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.034, 0.828, 0.403, ..., 0.188, 0.004, 0.28 ],\n",
       "       [0.008, 0.716, 0.556, ..., 0.224, 0.003, 0.261],\n",
       "       [0.04 , 0.924, 0.323, ..., 0.118, 0.003, 0.162],\n",
       "       ...,\n",
       "       [0.027, 0.651, 0.388, ..., 0.141, 0.001, 0.161],\n",
       "       [0.007, 0.838, 0.399, ..., 0.2  , 0.002, 0.313],\n",
       "       [0.008, 0.736, 0.554, ..., 0.241, 0.002, 0.182]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_printoptions(precision=3)\n",
    "normalizedX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Binarize Data (Make Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Binarizer().fit(X)\n",
    "binaryX = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "       [1., 1., 1., 0., 0., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_printoptions(precision=3)\n",
    "binaryX[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Irrelevant or partially relevant features can negatively impact\n",
    "model performance. In this chapter you will discover automatic feature selection techniques\n",
    "that you can use to prepare your machine learning data in Python with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 111.52  1411.887   17.605   53.108 2175.565  127.669    5.393  181.304]\n"
     ]
    }
   ],
   "source": [
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148.    0.   33.6  50. ]\n",
      " [ 85.    0.   26.6  31. ]\n",
      " [183.    0.   23.3  32. ]\n",
      " [ 89.   94.   28.1  21. ]\n",
      " [137.  168.   43.1  33. ]]\n"
     ]
    }
   ],
   "source": [
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features:  [ True False False False False  True  True False]\n",
      "Feature Ranking:  [1 2 4 5 6 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num Features:\", fit.n_features_) \n",
    "print(\"Selected Features: \", fit.support_)\n",
    "print(\"Feature Ranking: \", fit.ranking_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  [0.889 0.062 0.026]\n",
      "[[-2.022e-03  9.781e-02  1.609e-02  6.076e-02  9.931e-01  1.401e-02\n",
      "   5.372e-04 -3.565e-03]\n",
      " [-2.265e-02 -9.722e-01 -1.419e-01  5.786e-02  9.463e-02 -4.697e-02\n",
      "  -8.168e-04 -1.402e-01]\n",
      " [-2.246e-02  1.434e-01 -9.225e-01 -3.070e-01  2.098e-02 -1.324e-01\n",
      "  -6.400e-04 -1.255e-01]]\n"
     ]
    }
   ],
   "source": [
    "# summarize components\n",
    "print(\"Explained Variance: \",fit.explained_variance_ratio_)  \n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11  0.24  0.1   0.078 0.075 0.143 0.114 0.14 ]\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.656, 0.   , 0.   , 0.   , 0.193, 0.   , 0.151])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "model.fit(X, y)\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies 0.0\n",
      "Glucose 0.6564199687624899\n",
      "BloodPressure 0.0\n",
      "SkinThickness 0.0\n",
      "Insulin 0.0\n",
      "BMI 0.19253848413716962\n",
      "DiabetesPedigreeFunction 0.0\n",
      "Age 0.15104154710034046\n"
     ]
    }
   ],
   "source": [
    "for name, score in zip(df[df.columns], model.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SelectFromModel(model, prefit=True)\n",
    "x = clf.transform(X)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148. ,  33.6,  50. ],\n",
       "       [ 85. ,  26.6,  31. ],\n",
       "       [183. ,  23.3,  32. ],\n",
       "       ...,\n",
       "       [121. ,  26.2,  30. ],\n",
       "       [126. ,  30.1,  47. ],\n",
       "       [ 93. ,  30.4,  23. ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step: 4 Evaluate Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 3)\n",
      "(308, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.87012987012987\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "result = model.score(x_test, y_test)\n",
    "print(result * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuraccy: 76.570% (3.643%)\n"
     ]
    }
   ],
   "source": [
    "result = cross_val_score(model, x, y, cv=10, scoring='accuracy')\n",
    "print('Acuraccy: %.3f%%' % (result.mean()*100), '(%.3f%%)' % (result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.693%, (42.279%)\n"
     ]
    }
   ],
   "source": [
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "result = cross_val_score(model, x, y, cv=loocv)\n",
    "print(\"Accuracy: %.3f%%, (%.3f%%)\" %((result.mean()*100), (result.std()*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Random Test-Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.181%, (2.009%)\n"
     ]
    }
   ],
   "source": [
    "kfold = ShuffleSplit(n_splits=10, test_size=0.33, random_state=7)\n",
    "model = LogisticRegression()\n",
    "result = cross_val_score(model,x, y, cv=kfold)\n",
    "print(\"Accuracy: %.3f%%, (%.3f%%)\" %((result.mean()*100), (result.std()*100)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithm Performance Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics that you choose to evaluate your machine learning algorithms are very important.\n",
    "Choice of metrics influences how the performance of machine learning algorithms is measured\n",
    "and compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification problems are perhaps the most common type of machine learning problem and as\n",
    "such there are a myriad of metrics that can be used to evaluate predictions for these problems.\n",
    "\n",
    "In this section we will review how to use the following metrics:\n",
    "\n",
    " Classification Accuracy.\n",
    "\n",
    " Logarithmic Loss.\n",
    "\n",
    " Area Under ROC Curve.\n",
    "\n",
    " Confusion Matrix.\n",
    "\n",
    " Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classification Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770 (0.049)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "result = cross_val_score(model, x, y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (result.mean(), result.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -0.498 (0.067)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'neg_log_loss'\n",
    "result = cross_val_score(model, x, y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (result.mean(), result.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142  20]\n",
      " [ 35  57]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.33, random_state=7)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "matrix = confusion_matrix(y_test, y_predict)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.88      0.84       162\n",
      "         1.0       0.74      0.62      0.67        92\n",
      "\n",
      "    accuracy                           0.78       254\n",
      "   macro avg       0.77      0.75      0.76       254\n",
      "weighted avg       0.78      0.78      0.78       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.33, random_state=7)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "report = classification_report(y_test, y_predict)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.3 Regression Metrics\n",
    "In this section will review 3 of the most common metrics for evaluating predictions on regression\n",
    "\n",
    "machine learning problems:\n",
    "\n",
    " Mean Absolute Error.\n",
    "\n",
    " Mean Squared Error.\n",
    "\n",
    " R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print(boston.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -4.005 (2.084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "result = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\" %(result.mean(), result.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -34.705 (45.574)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "result = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\" %(result.mean(), result.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.203 (0.595)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "result = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\" %(result.mean(), result.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "X = df.values[:, 0:8]\n",
    "y = df.values[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate Machine Learning\n",
    "\n",
    "1. How to use pipelines to minimize data leakage.\n",
    "2. How to construct a data preparation and modeling pipeline.\n",
    "3. How to construct a feature extraction and modeling pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Modeling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773462064251538\n"
     ]
    }
   ],
   "source": [
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
    "model = Pipeline(estimators)\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Modeling Pipeline \n",
    "\n",
    "1. Feature Extraction with Principal Component Analysis (3 features).\n",
    "2. Feature Extraction with Statistical Selection (6 features).\n",
    "3. Feature Union.\n",
    "4. Learn a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "X = df.values[:, 0:8]\n",
    "y = df.values[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7773410799726589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create feature union\n",
    "features = []\n",
    "features.append(('pca', PCA(n_components=3)))\n",
    "features.append(('select_best', SelectKBest(k=6)))\n",
    "feature_union = FeatureUnion(features)\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('feature_union', feature_union))\n",
    "estimators.append(('logistic', LogisticRegression()))\n",
    "model = Pipeline(estimators)\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Improve Performance with Ensembles\n",
    "The three most popular methods for combining the predictions from different models are:\n",
    "\n",
    " Bagging. Building multiple models (typically of the same type) from different subsamples\n",
    "of the training dataset.\n",
    "\n",
    " Boosting. Building multiple models (typically of the same type) each of which learns to\n",
    "fix the prediction errors of a prior model in the sequence of models.\n",
    "\n",
    " Voting. Building multiple models (typically of differing types) and simple statistics (like\n",
    "calculating the mean) are used to combine predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Algorithms\n",
    "\n",
    "Bootstrap Aggregation (or Bagging) involves taking multiple samples from your training dataset\n",
    "(with replacement) and training a model for each sample. The final output prediction is averaged\n",
    "\n",
    "across the predictions of all of the sub-models. The three bagging models covered in this section\n",
    "\n",
    "are as follows:\n",
    "\n",
    " Bagged Decision Trees.\n",
    "\n",
    " Random Forest.\n",
    "\n",
    " Extra Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bagged Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.770745044429255\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7655844155844156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle = True)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656698564593302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "num_trees = 100\n",
    "max_features = 7\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle = True)\n",
    "model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.3 Boosting Algorithms\n",
    "Boosting ensemble algorithms creates a sequence of models that attempt to correct the mistakes\n",
    "of the models before them in the sequence. Once created, the models make predictions which\n",
    "may be weighted by their demonstrated accuracy and the results are combined to create a final\n",
    "output prediction. The two most common boosting ensemble machine learning algorithms are:\n",
    "\n",
    " AdaBoost.\n",
    "\n",
    " Stochastic Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "AdaBoost was perhaps the first successful boosting ensemble algorithm. It generally works\n",
    "by weighting instances in the dataset by how easy or difficult they are to classify, allowing\n",
    "the algorithm to pay or less attention to them in the construction of subsequent models. You\n",
    "can construct an AdaBoost model for classification using the AdaBoostClassifier class.\n",
    "\n",
    " The example below demonstrates the construction of 30 decision trees in sequence using the AdaBoost\n",
    "algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.760457963089542\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "num_trees = 30\n",
    "kfold = KFold(n_splits=10)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting\n",
    "Stochastic Gradient Boosting (also called Gradient Boosting Machines) are one of the most\n",
    "sophisticated ensemble techniques. It is also a technique that is proving to be perhaps one of\n",
    "the best techniques available for improving performance via ensembles. You can construct a\n",
    "Gradient Boosting model for classification using the GradientBoostingClassifier class. The example below demonstrates Stochastic Gradient Boosting for classification with 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604921394395079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "kfold = KFold(n_splits=10, random_state=seed, shuffle = True)\n",
    "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Voting Ensemble\n",
    "Voting is one of the simplest ways of combining the predictions from multiple machine learning\n",
    "algorithms. It works by first creating two or more standalone models from your training dataset.\n",
    "A Voting Classifier can then be used to wrap your models and average the predictions of the\n",
    "sub-models when asked to make predictions for new data. The predictions of the sub-models can\n",
    "be weighted, but specifying the weights for classifiers manually or even heuristically is difficult.\n",
    "More advanced methods can learn how to best weight the predictions from sub-models, but this\n",
    "is called stacking (stacked aggregation) and is currently not provided in scikit-learn.\n",
    "You can create a voting ensemble model for classification using the VotingClassifier\n",
    "class6\n",
    ". The code below provides an example of combining the predictions of logistic regression,\n",
    "classification and regression trees and support vector machines together for a classification\n",
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7616883116883117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/Users/user/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
